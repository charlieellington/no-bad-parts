# Build-Plan Summary

This project delivers a two-URL demo that pairs a Daily video call with a backstage AI "Silent Coach."  A **Partner** page embeds Daily Prebuilt and lets the user talk freely, while a **Facilitator** page shows the same call plus a live-updating sidebar of coaching hints generated by GPT-4.

Pipeline
1. **Audio in** – The agent (FastAPI + Pipecat) joins the call as `ai-coach`, subscribes only to the Partner's audio.
2. **Speech-to-Text** – Chunks are sent to OpenAI Whisper API (`whisper-1`).
3. **LLM** – Transcripts feed GPT-4 with a specialised SYSTEM_PROMPT; each response is a short IFS-style hint.
4. **Real-time delivery** – Hints are fanned out over a FastAPI WebSocket (`/ws`) to all connected facilitator browsers.

Stack Choices
• React / Next.js (Pages Router) + Tailwind & shadcn/ui for UI.  
• Pipecat for WebRTC transport + pipeline orchestration.  
• Fly.io for the Python container, Vercel for the Next.js front-end.

Milestones
1. Scaffold repo: session pages, FastAPI shell, local smoke tests.  
2. Embed Daily Prebuilt; prove video on both pages.  
3. Add WebSocket echo channel.  
4. Pipecat Daily transport → audio capture.  
5. Whisper + GPT-4 pipeline → send hints.  
6. Deploy agent to Fly, UI to Vercel.  
7. Final QA, monitoring, and future extensions (TTS, Deepgram, JWT auth).

## Goal

Create a two-URL proof-of-concept for "No Bad Parts" where:

1. The **Partner** joins a Daily video room and speaks naturally.
2. A **silent Agent** (running on a Fly.io container) joins the same room, captures only the Partner's audio, and sends it to OpenAI Whisper API for transcription.
3. The transcript is passed to **GPT-4** (or GPT-3.5-turbo in development) to generate a short Internal Family Systems--style coaching hint.
4. The hint text is streamed over a FastAPI WebSocket to the **Facilitator**'s browser.
5. The facilitator sees the video (via Daily Prebuilt) alongside a live-updating hint panel on a Vercel-hosted Next.js page.

## Stack Choices

- **Video interface**: Daily Prebuilt (https://www.daily.co/products/prebuilt-video-call-app/) -- embed via an `<iframe>` with almost no code.
- **Real-time AI orchestration**: Pipecat (https://docs.pipecat.ai/getting-started/overview) -- handles Daily WebRTC input, Whisper STT, GPT-4 LLM, and provides Python hooks.
- **Speech-to-text**: OpenAI Whisper API (model `whisper-1`) for accuracy and quick setup.
- **LLM**: GPT-4 for production (higher quality), GPT-3.5-turbo for development (lower cost).
- **Deployment**:
  - Fly.io for the Python agent container (FastAPI + Pipecat + WebSocket).
  - Vercel for the Next.js UI (Partner and Facilitator pages in the same repo).
- **Repository starting point**: https://github.com/charlieellington/no-bad-parts (monorepo that already contains a Next.js front-end and minimal Python agent scaffold).
- **Implementation approach**: Copy Daily's `pipecat-cloud-simple-chatbot` example (https://github.com/daily-co/pipecat-cloud-simple-chatbot) and modify it—remove TTS, change to GPT-4, add WebSocket broadcasting. This reuses battle-tested code. 